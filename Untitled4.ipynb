{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71b5e34c-59e3-4e6d-82a0-bd2ae53e3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from huggingface_hub import login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3911689-e7b7-4d93-bb4f-b5dd04ca37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HuggingFaceHub with the loaded token\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"tiiuae/falcon-7b-instruct\",\n",
    "    huggingfacehub_api_token=\"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\",  # Token loaded from .env\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_length\": 200}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4802f5d1-2cb9-4e8e-88fa-549b939dab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define a prompt template for the chatbot\n",
    "template = \"\"\"\n",
    "You are a helpful question-answering AI. Answer the following .\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create a prompt template using LangChain's PromptTemplate class\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4dd8bd8-e004-48bb-a47e-ef39f37d9215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falcon 7B-Instruct Q&A Chatbot is ready. Type your question or type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  what is capital of india\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falcon: \n",
      "You are a helpful question-answering AI. Answer the following .\n",
      "\n",
      "Question: what is capital of india\n",
      "Answer:\n",
      "The capital of India is New Delhi.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  do you know about taj mahal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falcon: \n",
      "You are a helpful question-answering AI. Answer the following .\n",
      "\n",
      "Question: do you know about taj mahal\n",
      "Answer:\n",
      "True\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  tail me about taj mahal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falcon: \n",
      "You are a helpful question-answering AI. Answer the following .\n",
      "\n",
      "Question: tail me about taj mahal\n",
      "Answer:\n",
      "The Taj Mahal is a famous and awe-inspiring monument located in India. It is a beautiful white marble structure that stands majestically on a raised platform at the end of a long, wide axis. The Taj Mahal is a masterpiece of Islamic architecture and is one of the most popular tourist attractions in the world. It is renowned for its meticulous craftsmanship, intricate details, and breathtaking views that make it a must-see for any traveler.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# 4. Create the LLMChain with the LLM and prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 5. Define a function to ask a question using the LLMChain\n",
    "def ask_falcon_llm_chain(question):\n",
    "    return llm_chain.run({\"question\": question})\n",
    "\n",
    "# 6. Main chatbot loop\n",
    "def chatbot():\n",
    "    print(\"Falcon 7B-Instruct Q&A Chatbot is ready. Type your question or type 'exit' to quit.\")\n",
    "    while True:\n",
    "        question = input(\"\\nYou: \")\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        answer = ask_falcon_llm_chain(question)\n",
    "        print(f\"Falcon: {answer}\")\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1ace5-5cc6-43a8-87e3-f3b39bec96e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
